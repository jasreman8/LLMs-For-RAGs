# LLMs-For-RAGs
This repository contains all projects that were created while learning to create RAG systems using LLMs.

**Project 1:** Creating a RAG-based Q&A system for PowerBI documentation:
- Built a Retrieval-Augmented Generation (RAG) pipeline to enable real-time Q&A over PowerBI documentation
- Created and managed document embeddings using ChromaDB vector store
- Implemented CRUD operations for vector ingestion, updates, and retrieval
- Enabled context-grounded responses for Power BI features, functions, and best practices

**Project 2:** Adding RAG-based Q&A system for health insurance policy comprehension:
- Built a Retrieval-Augmented Generation (RAG) pipeline to enable natural language Q&A over health insurance policy documents
- Created a persistent ChromaDB vector store populated with policy document embeddings
- Instantiated and managed a Chroma client for vector storage and retrieval
- Implemented CRUD operations to maintain and update policy embeddings
- Enabled context-grounded responses to improve accessibility and understanding of insurance policies

**Project 3:** Implementing vector database CRUD operations using LangChain and ChromaDB:
- Created a persistent ChromaDB vector store populated with five years of Tesla earnings records
- Implemented length-based document chunking across a folder of financial documents
- Used LangChain abstractions to manage vector storage and retrieval
- Performed read, update, and delete operations on stored embeddings
